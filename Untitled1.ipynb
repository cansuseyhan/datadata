{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAN8vbbUN0e7"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "z = zipfile.ZipFile(\"kagglecatsanddogs_5340.zip\")\n",
        "z.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "metadata": {
        "id": "WMvKne8LN2BW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "for i in os.listdir(\"PetImages\"):\n",
        "  for j in os.listdir(\"PetImages/\"+i): \n",
        "    if i ==  \"Cat\":\n",
        "      labels.append(0)\n",
        "    else:\n",
        "      labels.append(1)\n",
        "    images.append(os.path.join(\"PetImages\",i,j)) \n",
        "print(images[0],labels[0])\n",
        "df_images = pd.DataFrame(images)\n",
        "df_labels = pd.DataFrame(labels)\n",
        "df = pd.concat([df_images,df_labels],axis=1)\n",
        "df.columns = [\"images\",\"labels\"]\n",
        "df.head()\n",
        "df.info()"
      ],
      "metadata": {
        "id": "mdAEqLe4N5eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "for index,link in enumerate(df[\"images\"][:12499]):\n",
        "    images = Image.open(link).convert('RGB')\n",
        "    images = images.resize((500,500),Image.ANTIALIAS)\n",
        "    \n",
        "\n",
        "    dir_path = \"C:\\\\Users\\\\Desktop\\\\PetImages_Resize\\\\Cat_Resize\"    \n",
        "\n",
        "    cansu = str(index)+\".jpg\"\n",
        "    file_path = os.path.join( dir_path, cansu  ) \n",
        "    images.save( file_path )\n",
        "for index,link in enumerate(df[\"images\"][12499:]):\n",
        "    images = Image.open(link).convert('RGB')\n",
        "    images = images.resize((500,500),Image.ANTIALIAS)\n",
        "   \n",
        "\n",
        "    dir_path = \"C:\\Users\\\\Desktop\\\\PetImages_Resize\\\\Dog_Resize\"    \n",
        "\n",
        "    cansu = str(index)+\".jpg\"\n",
        "    file_path = os.path.join( dir_path, cansu  ) \n",
        "    images.save( file_path )\n",
        "    images_resize = []\n",
        "    labels_resize = []\n",
        "    for i in os.listdir(\"PetImages_Resize\"):\n",
        "      for j in os.listdir(\"PetImages_Resize/\"+i): \n",
        "        if i ==  \"Cat_Resize\":\n",
        "          labels_resize.append(0)\n",
        "        else:\n",
        "          labels_resize.append(1)\n",
        "        images_resize.append(os.path.join(\"PetImages_Resize\",i,j)) \n",
        "    print(images_resize[0],labels_resize[0])\n",
        "    df_images = pd.DataFrame(images_resize)\n",
        "df_labels = pd.DataFrame(labels_resize)\n",
        "df = pd.concat([df_images,df_labels],axis=1)\n",
        "df.columns = [\"images\",\"labels\"]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2kY5F11tOBbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "list = []\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "dogs = df[\"images\"].loc[df[\"labels\"] == 1]\n",
        "for i in range(25):\n",
        "    cansu = random.randint(12501,25000)\n",
        "    list.append(df[\"images\"].iloc[cansu])\n",
        "for index,i in enumerate(list):\n",
        "    plt.subplot(5,5,index+1) \n",
        "    image = load_img(i)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Dogs\")\n",
        "import random\n",
        "list_2 = []\n",
        "plt.figure(figsize=(20,20))\n",
        "cats = df[\"images\"].loc[df[\"labels\"] == 0]\n",
        "for i in range(25):\n",
        "    cansu = random.randint(0,12499)\n",
        "    list_2.append(df[\"images\"].iloc[cansu])\n",
        "\n",
        "for index,i in enumerate(list_2):\n",
        "    plt.subplot(5,5,index+1) \n",
        "    image = load_img(i)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Cats\")\n",
        "import seaborn as sns\n",
        "sns.countplot(df[\"labels\"])\n",
        "df['labels'] = df['labels'].astype('str')\n",
        "from sklearn.model_selection import train_test_split\n",
        "train,test = train_test_split(df,test_size=0.33,random_state=42)\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,  \n",
        "    rotation_range = 40, \n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "val_generator = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_iterator = train_generator.flow_from_dataframe(\n",
        "    train, \n",
        "    x_col='images', \n",
        "    y_col='label', \n",
        "    target_size=(128,128), \n",
        "    batch_size=512, \n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_iterator = val_generator.flow_from_dataframe(\n",
        "    test, \n",
        "    x_col='images', \n",
        "    y_col='label', \n",
        "    target_size=(128,128), \n",
        "    batch_size=512, \n",
        "    class_mode='binary'\n",
        ")\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "model = Sequential([\n",
        "                    Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),\n",
        "                    MaxPool2D((2,2)),\n",
        "                    Conv2D(32, (3,3), activation='relu'),\n",
        "                    MaxPool2D((2,2)),\n",
        "                    Conv2D(64, (3,3), activation='relu'),\n",
        "                    MaxPool2D((2,2)),\n",
        "                    Flatten(),\n",
        "                    Dense(512, activation='relu'),\n",
        "                    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit(train_iterator, epochs=10, validation_data=val_iterator)"
      ],
      "metadata": {
        "id": "ZDSG_H4HOE6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Accuracy Graph')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Loss Graph')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7UiLBhGMONZb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}